{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0186cc-b77d-4841-a162-3a2e41ce77eb",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "66168eb0-3401-4854-ad20-7babad3fe06b",
   "metadata": {},
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import src.data.util as du\n",
    "import src.text.tokenizer as tk\n",
    "\n",
    "d90_file = '../results/complexity_utf-16_10_10_2002_bibles_90_lcm.csv'\n",
    "dall_file = '../results/complexity_utf-16_10_10_2002_bibles_lcm.csv'\n",
    "family_file = '../dataset/family.csv'\n",
    "\n",
    "bible_file_d90 = '../dataset/' + re.match('.*(bibles_.*)', d90_file).group(1)\n",
    "bibles_d90 = pd.read_csv(bible_file_d90, index_col=False)\n",
    "bibles_d90 = bibles_d90[bibles_d90.language != 'NAMBIKUÁRA']\n",
    "\n",
    "df90 = pd.read_csv(d90_file, index_col=False)\n",
    "df90 = df90[df90.language != 'NAMBIKUÁRA'] # We removed Nambikuára because it has tone annotation\n",
    "df90.loc[df90.metric == 'del-chars', 'value'] = - df90.loc[df90.metric == 'del-chars', 'value']\n",
    "df90.loc[df90.metric == 'rep-words', 'value'] = 1/df90.loc[df90.metric == 'rep-words', 'value']\n",
    "\n",
    "bible_file_dall = '../dataset/' + re.match('.*(bibles_.*)', dall_file).group(1)\n",
    "bibles_dall = pd.read_csv(bible_file_dall, index_col=False)\n",
    "bibles_dall = bibles_dall[bibles_dall.language != 'NAMBIKUÁRA']\n",
    "\n",
    "dfall = pd.read_csv(dall_file, index_col=False)\n",
    "dfall = dfall[dfall.language != 'NAMBIKUÁRA'] # We removed Nambikuára because it has tone annotation\n",
    "dfall.loc[dfall.metric == 'del-chars', 'value'] = - dfall.loc[dfall.metric == 'del-chars', 'value']\n",
    "dfall.loc[dfall.metric == 'rep-words', 'value'] = 1/dfall.loc[dfall.metric == 'rep-words', 'value']\n",
    "\n",
    "family = pd.read_csv(family_file, index_col=None)\n",
    "\n",
    "dfall = dfall.drop(columns=['language']).merge(\n",
    "    family.drop(\n",
    "        columns=['countries', 'branch']\n",
    "    ), on='wals', how='inner').rename(columns={ 'wals' : 'code'})\n",
    "df90 = df90.drop(columns=['language']).merge(\n",
    "    family.drop(\n",
    "        columns=['countries', 'branch'])\n",
    "    , on='wals', how='inner').rename(columns={ 'wals' : 'code'})\n",
    "\n",
    "metric_rename = {'del-chars'  : r'morphological deletion',\n",
    "                 'del-verses' : r'pragmatic deletion',\n",
    "                 'del-words'  : r'syntactic deletion',\n",
    "                 'rep-words'  : r'morphological substitution',\n",
    "                 'do-nothing' : r'size'\n",
    "                }\n",
    "\n",
    "dfall = dfall.replace(metric_rename)\n",
    "df90 = df90.replace(metric_rename)\n",
    "\n",
    "\n",
    "rall = dfall.groupby(\n",
    "    by=['language', 'family', 'code', 'metric', 'algorithm'],\n",
    "    as_index=False).agg({'value' : ['mean', 'var']})\n",
    "r90 = df90.groupby(\n",
    "    by=['language', 'family', 'code', 'metric', 'algorithm'],\n",
    "    as_index=False).agg({'value' : ['mean', 'var']})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6d892938-f5b7-47bc-a351-a6b29aca5b5c",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0b9a3b2-3c1f-45a8-8c17-241e709e6038",
   "metadata": {},
   "source": [
    "def compute_numtypes_numtokens(df):\n",
    "    langs = du.by_field(df, 'language')\n",
    "    united = {\n",
    "        lang : du.df_to_str(val)\n",
    "        for lang, val in langs.items()\n",
    "    }\n",
    "\n",
    "    d = dict(language=[], tokens=[], types=[])\n",
    "    for lang, text in united.items():\n",
    "        d['language'].append(lang)\n",
    "        tokens = tk.tokens(text)\n",
    "        d['tokens'].append(len(tokens))\n",
    "        d['types'].append(len(tk.types(tokens)))\n",
    "    return d\n",
    "\n",
    "\n",
    "def compute_num_chars(df):\n",
    "    from collections import Counter\n",
    "    d = dict(language=[], chars=[])\n",
    "    for lang in set(df.language):\n",
    "        c = Counter('\\n'.join(df[df.language == lang].text))\n",
    "        d['language'].append(lang)\n",
    "        d['chars'].append(len(c))\n",
    "    dd = pd.DataFrame(d)\n",
    "    return dd\n",
    "\n",
    "\n",
    "def num_chars_across_bible(df, bibles):\n",
    "    nc = compute_num_chars(bibles).sort_values('language').reset_index().drop(columns='index').chars.to_numpy()\n",
    "    out = h1(df)\n",
    "    for algo, (dfs, _, __) in out.items():\n",
    "        if algo == 'none': continue\n",
    "        y = dfs.drop_duplicates('language').sort_values('language').reset_index().drop(columns='index').oc.to_numpy()\n",
    "        r = sp.stats.pearsonr(nc, y)\n",
    "        print(\"%6s statistic: %.5f pvalue: %.5f\" % (algo, r.statistic, r.pvalue))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bef9e6ef-6ede-4b1a-9165-fb52cc8ef055",
   "metadata": {},
   "source": [
    "# H1 Overall complexity of a text\n",
    "\n",
    "The overall complexity of a text in its\n",
    "original language is lower than in the other\n",
    "languages, as a result of the introduction\n",
    "of cultural clarification in the translation process.\n",
    "The language complexity of a translated text should be greater than their counterpart in the source language."
   ]
  },
  {
   "cell_type": "code",
   "id": "3dfd5f70-1d50-4599-a819-e03ea53071d8",
   "metadata": {},
   "source": [
    "def h1(df):\n",
    "    unique_algorithms = list(df.algorithm.unique())\n",
    "    out = {}\n",
    "    for algorithm in unique_algorithms:\n",
    "        ag = df.algorithm == algorithm\n",
    "        nn = df.algorithm == 'none'\n",
    "        sz = df.metric == 'size'\n",
    "        rw = df[sz & nn]\n",
    "        co = df[sz & ag]\n",
    "\n",
    "        x = rw.sort_values('language').value.to_numpy()\n",
    "        y = co.sort_values('language').value.to_numpy()\n",
    "        \n",
    "        if np.unique(x).size > 1:  # Verifica se há mais de um valor único em x\n",
    "            lr = sp.stats.linregress(x, y)\n",
    "            ỹ = lr.slope * x + lr.intercept\n",
    "            oc = y - ỹ\n",
    "            out[algorithm] = (\n",
    "                pd.DataFrame(dict(language=list(rw.sort_values('language').language),\n",
    "                                  oc=oc, rw=x, co=y)),\n",
    "                x,\n",
    "                ỹ                 \n",
    "            )\n",
    "        else:\n",
    "            print(f\"Skipping linear regression for {algorithm} because all x values are identical.\")\n",
    "            out[algorithm] = (None, None, None)  # Armazenar None para o caso de erro\n",
    "\n",
    "    return out\n",
    "\n",
    "def plth1(df, title=None):\n",
    "    out = h1(df)\n",
    "    fig, ax = plt.subplots(1, len(out), figsize=(5 * len(out), 5))\n",
    "\n",
    "    for i, (algo, (dfr, x, ỹ)) in enumerate(out.items()):\n",
    "        if x is not None and ỹ is not None:  # Verifica se x e ỹ são válidos\n",
    "            ax[i].plot(x, ỹ)\n",
    "            ax[i].scatter(dfr['rw'], dfr['co'])\n",
    "            ax[i].set_title(fr'$\\it{{{algo}}}$')\n",
    "            ax[i].set_xlabel('size in bytes')\n",
    "            ax[i].set_ylabel('size in bytes compressed')\n",
    "        else:\n",
    "            ax[i].set_title(f\"{algo} - No data\")\n",
    "            ax[i].set_xlabel('size in bytes')\n",
    "            ax[i].set_ylabel('size in bytes compressed')\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    fig.tight_layout()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a30905f9-90a2-47ce-8ff8-764e05257704",
   "metadata": {},
   "source": [
    "## D90 Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "4c0508b3-d297-483f-b5eb-6dbc60c282b1",
   "metadata": {},
   "source": [
    "out90 = h1(df90)\n",
    "plth1(df90, title=r\"$\\mathcal{H}_1$ - D90 subset\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb15072a-234d-4ded-b1d0-ceaab53100cc",
   "metadata": {},
   "source": [
    "num_chars_across_bible(df90, bibles_d90)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bad491d8-ac71-4b35-9fe5-0fe197f5b699",
   "metadata": {},
   "source": [
    "l = 'Sateré-Mawé'\n",
    "num_chars_across_bible(df90[df90.language != l], bibles_d90[bibles_d90.language != l.upper()])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "91771f8d-752a-4b2f-b5cd-c1f51e11004a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DALL Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "c41c27f6-4723-4746-836b-ce488f8c85c7",
   "metadata": {},
   "source": [
    "outall = h1(dfall)\n",
    "plth1(dfall, title=r\"$\\mathcal{H}_1$ - DALL subset\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e7978442-a142-44e0-9715-862fa116c77c",
   "metadata": {},
   "source": [
    "num_chars_across_bible(dfall, bibles_dall)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97220b28-077b-49e0-8680-bca1e0c6aaa5",
   "metadata": {},
   "source": [
    "l = 'Sateré-Mawé'\n",
    "num_chars_across_bible(dfall[dfall.language != l], bibles_dall[bibles_dall.language != l.upper()])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ca9dd9d2-0fd7-4b0c-9ae3-2437a9e692a9",
   "metadata": {},
   "source": [
    "# H2 Content invariance\n",
    "For any complexity measure, Bible complexity should be the same (independenlty of translation).\n",
    "In this case, we should observe a smaller variance in size in bytes of the compressed texts in comparison with\n",
    "the uncompressed texts."
   ]
  },
  {
   "cell_type": "code",
   "id": "e45494a4-4056-4096-a71c-c9df31a0323b",
   "metadata": {},
   "source": [
    "def h2(rdf):\n",
    "    H2 = rdf.groupby(by=['metric', 'algorithm'],\n",
    "                     as_index=False).agg({('value', 'mean') : ['mean', 'var']})\n",
    "\n",
    "    for algorithm in ['gzip', 'bz2']:\n",
    "        x = np.log10(\n",
    "            H2[(H2.metric == 'size') \\\n",
    "            & (H2.algorithm == algorithm)][('value', 'mean', 'var')].item()\n",
    "        )\n",
    "        y = np.log10(\n",
    "            H2[(H2.metric == 'size') \\\n",
    "            & (H2.algorithm == 'none')][('value', 'mean', 'var')].item()\n",
    "        )\n",
    "        print('%-4s variance has %d decimal places\\n\\tOriginal size variance has %d decimal places' \\\n",
    "              % (algorithm, int(np.ceil(x)), int(np.ceil(y))))\n",
    "\n",
    "def ploth2(outdf, text):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.suptitle(f\"Overall Complexity Distribution through the Evaluated Languages for {text} Subset\")\n",
    "    ax.hist(x='oc', bins=10, data=outdf['gzip'][0], label='gzip')\n",
    "    ax.hist(x='oc', bins=10, data=outdf['bz2'][0], label='bz2')\n",
    "    ax.set_xlabel('Residuals')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2882a230-9205-4834-962a-068cdf72194a",
   "metadata": {},
   "source": [
    "## D90 Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "76064f35-14b7-492e-a354-86ffe06def93",
   "metadata": {},
   "source": [
    "h2(r90)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e82e8bd-5183-4af2-93e3-25f0268d9034",
   "metadata": {},
   "source": [
    "ploth2(out90, \"D90\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4a6589d1-a5fe-4b0b-ba33-39faa396c5f8",
   "metadata": {},
   "source": [
    "## DALL Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d97853b-9f63-44d3-b238-210e4d5a22af",
   "metadata": {},
   "source": [
    "h2(rall)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3b433b67-9152-48a6-9e63-1730355fbbbc",
   "metadata": {},
   "source": [
    "ploth2(outall, \"DALL\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a05f384d-8df8-422c-9165-ab9ef81a7835",
   "metadata": {},
   "source": [
    "# H3 Morphology and Syntatic trade-off\n",
    "Languages that have a higher morphological complexity show a smaller syntatic complexity and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "id": "49df0783-d7c3-455e-989a-883ed7946909",
   "metadata": {},
   "source": [
    "def h3(df):\n",
    "    metrics = ['morphological deletion', 'syntactic deletion']\n",
    "    algorithms = ['gzip', 'bz2']\n",
    "\n",
    "    for i, algorithm in enumerate(algorithms):\n",
    "        print('Algorithm %6s' % algorithm)\n",
    "        a = df.algorithm == algorithm\n",
    "        xs = [df[(df.metric == metric) & a][('value', 'mean')] for metric in metrics]\n",
    "        cr =  sp.stats.pearsonr(xs[0], xs[1])\n",
    "        print('\\tPearson Correlation: statistic: %.4f p-value: %.4f' % (cr.statistic, cr.pvalue))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ffe3080-86ce-4d76-bb85-cdec6052c653",
   "metadata": {},
   "source": [
    "## D90 Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "85c15b41-7fc3-48fb-bdc6-da967cf5789c",
   "metadata": {},
   "source": [
    "print('All languages')\n",
    "h3(r90)\n",
    "\n",
    "indo_european_languages = (\"Ancient Greek\", \"English\", \"French\", \"Germany\", \"Portuguese\", \"Spanish\")\n",
    "\n",
    "r90_iel = r90[r90.language.isin(indo_european_languages)]\n",
    "\n",
    "print('\\nOnly Indo-European Languages')\n",
    "h3(r90_iel)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eefaa67e-fd42-421d-9ee2-24c5d2f6f800",
   "metadata": {},
   "source": [
    "## DALL Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "13771dc8-625a-4683-807c-0733ca7a9bd0",
   "metadata": {},
   "source": [
    "print('All languages')\n",
    "h3(rall)\n",
    "\n",
    "indo_european_languages = (\"Ancient Greek\", \"English\", \"French\", \"Germany\", \"Portuguese\", \"Spanish\")\n",
    "\n",
    "rall_iel = rall[rall.language.isin(indo_european_languages)]\n",
    "\n",
    "print('\\nOnly Indo-European Languages')\n",
    "h3(r90_iel)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0b1b1a8b-1011-474e-b0c4-5c3c81004b84",
   "metadata": {},
   "source": [
    "# O1 Morphological Complexity, tokens and types\n",
    "a) There exists a **positive** correlation between morphological complexity and **the number of types** in a sample.\n",
    "\n",
    "b) There exists a **negative** correlation between morphological complexity and **the number of tokens** in a sample."
   ]
  },
  {
   "cell_type": "code",
   "id": "043c333b-6af4-49cf-a8cc-2a592a94e387",
   "metadata": {},
   "source": [
    "def o1(df, bibles):\n",
    "    d = compute_numtypes_numtokens(bibles)\n",
    "    \n",
    "    tdf = pd.DataFrame(d).sort_values('language')\n",
    "\n",
    "    metric = df.metric == 'morphological substitution'\n",
    "    gzip = df.algorithm == 'gzip'\n",
    "    bz2 = df.algorithm == 'bz2'\n",
    "    repwords_gzip = df[metric & gzip].groupby(\n",
    "        by='language').agg({'value' : 'mean'}).value.to_numpy()\n",
    "    repwords_bz2 = df[metric & bz2].groupby(\n",
    "        by='language').agg({'value' : 'mean'}).value.to_numpy()\n",
    "\n",
    "    s = \"%s) corr=%0.4f, p-value=%g\"\n",
    "    \n",
    "    print(\"Gzip results:\")\n",
    "    a = sp.stats.pearsonr(tdf.types.to_numpy(), repwords_gzip)#.value.to_numpy())\n",
    "    b = sp.stats.pearsonr(tdf.tokens.to_numpy(), repwords_gzip)#.value.to_numpy())\n",
    "    print(s % (\"a\", a.statistic, a.pvalue))\n",
    "    print(s % (\"b\", b.statistic, b.pvalue))\n",
    "    \n",
    "    print(\"\\nBz2 results:\")\n",
    "    a = sp.stats.pearsonr(tdf.types.to_numpy(), repwords_bz2)#.value.to_numpy())\n",
    "    b = sp.stats.pearsonr(tdf.tokens.to_numpy(), repwords_bz2)#.value.to_numpy())\n",
    "    print(s % (\"a\", a.statistic, a.pvalue))\n",
    "    print(s % (\"b\", b.statistic, b.pvalue))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4625493e-a404-45a2-aef7-96cb5b0a44ce",
   "metadata": {},
   "source": [
    "## D90 Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb83db76-6ab3-46be-b501-0ed9eb2d5a5b",
   "metadata": {},
   "source": [
    "o1(df90, bibles_d90)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "662a4904-88f3-4d3d-a824-db2c9dcf3f05",
   "metadata": {},
   "source": [
    "## DALL Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "13f8cada-9bf8-4d4f-b029-4c5ed3dd56aa",
   "metadata": {},
   "source": [
    "o1(dfall, bibles_dall)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "812bc366-7eac-4cf0-9ab3-735edac6e744",
   "metadata": {},
   "source": [
    "# O2 All languages are equal in a pragmatic sense\n",
    "The varinace of the pragmatic complexity should be the smallest."
   ]
  },
  {
   "cell_type": "code",
   "id": "3f8812bd-2a4f-4be3-aa01-8cae471f47df",
   "metadata": {},
   "source": [
    "# Wrap this code in a function, call for each subset\n",
    "def o2(rdf):\n",
    "    sz = rdf.metric == 'size'\n",
    "    nn = rdf.algorithm == 'none'\n",
    "    out = rdf.loc[~sz & ~nn].groupby(\n",
    "        by=['metric', 'algorithm']).agg({'value' : 'var'}).sort_values('value')\n",
    "\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9f6c4a4c-2a21-4964-872e-c9ac4379a43d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## D90 Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "428cf269-8585-4232-9bdd-a01796b3bcd0",
   "metadata": {},
   "source": [
    "o2(df90)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "483e584c-7f85-4db0-bcf9-9897f0f96421",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DALL Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "9480207d-f0fc-4e0e-a5bf-d53eab26fa35",
   "metadata": {},
   "source": [
    "o2(dfall)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0478eacf-3d5d-4dac-9ece-75f66a784161",
   "metadata": {},
   "source": [
    "# O3 Morphological complexity metric agrees with Nichol's"
   ]
  },
  {
   "cell_type": "code",
   "id": "4395414e-9573-4a52-9aea-9e461711035c",
   "metadata": {},
   "source": [
    "nichols_complexity = pd.read_csv('../dataset/complexity_ldst.csv', index_col=None)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9c5bdb4d-fa57-4d06-b541-2eed7bd48b48",
   "metadata": {},
   "source": [
    "def o3(df, nc, languages, metric_str, algorithm_str):\n",
    "    def language_set(languages):\n",
    "        return set(map(lambda s: s.lower().capitalize(), languages))\n",
    "\n",
    "    def language_unset(languages):\n",
    "        return set(map(lambda s: s.upper(), languages))\n",
    "\n",
    "    langs = language_set(languages) & language_set(df.language)\n",
    "\n",
    "    langsi = df.language.isin(langs)\n",
    "    metric = df.metric == metric_str\n",
    "    algorithm = df.algorithm == algorithm_str\n",
    "    a = df[langsi & metric & algorithm].sort_values('language')[('value', 'mean')].to_numpy()\n",
    "    b = nc[nc.language.isin(language_unset(langs))].sort_values('language')['value'].to_numpy()\n",
    "    r = sp.stats.pearsonr(a, b)\n",
    "    print('%r %s %s -> pearsonr=%0.4f p-value=%g' % (langs, metric_str, algorithm_str, r.statistic, r.pvalue))\n",
    "    #return sp.stats.pearsonr(a, b)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e9272d4-0371-4de3-954c-62033ebc49f6",
   "metadata": {},
   "source": [
    "## D90 Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "b83fe5ec-695c-47de-8685-1fd66136a9fa",
   "metadata": {},
   "source": [
    "o3(r90, nichols_complexity, nichols_complexity.language, 'morphological deletion', 'gzip')\n",
    "o3(r90, nichols_complexity, nichols_complexity.language, 'morphological deletion', 'bz2')\n",
    "\n",
    "o3(r90, nichols_complexity, nichols_complexity.language, 'morphological substitution', 'gzip')\n",
    "o3(r90, nichols_complexity, nichols_complexity.language, 'morphological substitution', 'bz2')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35a88bfe-4ce7-4f0d-a546-3d2989ff719b",
   "metadata": {},
   "source": [
    "## DALL Subset"
   ]
  },
  {
   "cell_type": "code",
   "id": "aa0c0768-3102-4e43-a6ba-9acd763870d2",
   "metadata": {},
   "source": [
    "o3(r90, nichols_complexity, nichols_complexity.language, 'morphological deletion', 'gzip')\n",
    "o3(r90, nichols_complexity, nichols_complexity.language, 'morphological deletion', 'bz2')\n",
    "\n",
    "o3(r90, nichols_complexity, nichols_complexity.language, 'morphological substitution', 'gzip')\n",
    "o3(r90, nichols_complexity, nichols_complexity.language, 'morphological substitution', 'bz2')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "70585133-c3c7-4dda-a726-2cd6d1d8f62c",
   "metadata": {},
   "source": [
    "# O4 Compression algorithm independence\n",
    "The results are equivalent wheter using **Gzip** or **Bz2**."
   ]
  },
  {
   "cell_type": "code",
   "id": "aaa70086-bc74-486e-9a19-589ba62ed801",
   "metadata": {},
   "source": [
    "def o4(df, metric, algo):\n",
    "    m = df.metric == metric\n",
    "    a = df.algorithm == algo\n",
    "\n",
    "    ret = df[m & a].sort_values(('value', 'mean'))\n",
    "    return ret"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ba087f1c-bd19-4a04-82c8-d902a9976987",
   "metadata": {},
   "source": [
    "## D90 Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f1220-77d5-40d3-8c4d-1d46698d0992",
   "metadata": {},
   "source": [
    "### Morphological Substitution"
   ]
  },
  {
   "cell_type": "code",
   "id": "fa4c56e9-ea99-4c17-81b4-5c1e31da3a17",
   "metadata": {},
   "source": [
    "o4(r90, 'morphological substitution', 'gzip')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d4bef29-f94c-43e6-8c3e-9e5706f1ef0d",
   "metadata": {},
   "source": [
    "o4(r90, 'morphological substitution', 'bz2')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a108bf41-82e0-4686-abbb-b6bceb60e8fd",
   "metadata": {},
   "source": [
    "### Morphological Deletion"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9e3ba77-b81c-40d3-8aa6-f6a8bb8acb62",
   "metadata": {},
   "source": [
    "o4(r90, 'morphological deletion', 'gzip')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "53332773-d067-4000-84cc-10ce146ab282",
   "metadata": {},
   "source": [
    "o4(r90, 'morphological deletion', 'bz2')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f2da0b29-7502-48e3-ad00-297fa89a9bf4",
   "metadata": {},
   "source": [
    "## DALL Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c24285b-d6df-4d14-a6f7-15a909571351",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Morphological Substitution"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f1dba2a-348b-4574-bd6e-ec993c3f5da4",
   "metadata": {},
   "source": [
    "o4(rall, 'morphological substitution', 'gzip')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3ac224e-d813-4b5c-80af-d9a633f66d42",
   "metadata": {},
   "source": [
    "o4(r90, 'morphological substitution', 'bz2')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ccaf9401-8c4a-4585-897e-6798fff2b8a6",
   "metadata": {},
   "source": [
    "### Morphological Deletion"
   ]
  },
  {
   "cell_type": "code",
   "id": "d60d794d-4ef9-42e5-94d5-139087cfc5bf",
   "metadata": {},
   "source": [
    "o4(r90, 'morphological deletion', 'gzip')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27e1d2bc-8b56-4b71-9228-c77d3ca87642",
   "metadata": {},
   "source": [
    "o4(r90, 'morphological deletion', 'bz2')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
